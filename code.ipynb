{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8ecbbb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Import Dataset and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a936a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%pip install imbalanced-learn==0.10.1\n",
    "%pip install catboost==1.1.1\n",
    "%pip install pycountry==22.1.10\n",
    "%pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fdcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score, roc_auc_score)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "TRAIN_FILE = \"./train.csv\"\n",
    "TEST_FILE = \"./submission.csv\"\n",
    "MODEL_FILE = \"./catboost_params.pkl\"\n",
    "\n",
    "DO_OPTIMIZATION = False\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfc41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "df_test = pd.read_csv(TEST_FILE)\n",
    "df_submission = pd.read_csv(TEST_FILE)\n",
    "\n",
    "X, y = df_train.drop(\"is_converted\", axis=1), df_train[\"is_converted\"]\n",
    "X_test = df_test.drop([\"is_converted\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb1913",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8770cab",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 1. Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41800200",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {\n",
    "    **{column: 0 for column in X.columns},\n",
    "    \"inquiry_type\": \"Quotation or Purchase Consultation\",\n",
    "    \"customer_country\": \"Not Found\",\n",
    "}\n",
    "\n",
    "X.fillna(value=values, inplace=True)\n",
    "X_test.fillna(value=values, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f4781",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## 2. Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6efdfe5",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Feature: Expected Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866093c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_timeline_remap(line):\n",
    "    if not isinstance(line, str):\n",
    "        return np.nan\n",
    "\n",
    "    line = (\n",
    "        line.lower()\n",
    "        .strip()\n",
    "        .replace(\"then\", \"than\")\n",
    "        .replace(\"_\", \"\")\n",
    "        .replace(\"~\", \"\")\n",
    "        .replace(\" \", \"\")\n",
    "        .replace(\"-\", \"\")\n",
    "    )\n",
    "\n",
    "    if line in [\"lessthan3months\", \"onemonth\"]:\n",
    "        return 1.5\n",
    "    elif line in [\"3months6months\", \"lessthan6months\", \"lessthan5months\"]:\n",
    "        return 4.5\n",
    "    elif line == \"6months9months\":\n",
    "        return 7.5\n",
    "    elif line == \"9months1year\":\n",
    "        return 10.5\n",
    "    elif line == \"morethanayear\":\n",
    "        return 12\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "X[\"expected_timeline\"] = [\n",
    "    expected_timeline_remap(x) for x in X[\"expected_timeline\"].values\n",
    "]\n",
    "X_test[\"expected_timeline\"] = [\n",
    "    expected_timeline_remap(x) for x in X_test[\"expected_timeline\"].values\n",
    "]\n",
    "\n",
    "X[\"expected_timeline\"].fillna(X[\"expected_timeline\"].mean(), inplace=True)\n",
    "X_test[\"expected_timeline\"].fillna(X[\"expected_timeline\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e431ad9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Feature: Customer Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_country(country):\n",
    "    if not isinstance(country, str):\n",
    "        return \"Not Found\"\n",
    "\n",
    "    country = country.split(\"/\")[-1].strip()\n",
    "    country = pycountry.countries.get(name=country)\n",
    "    return \"Not Found\" if country is None else country.alpha_3\n",
    "\n",
    "\n",
    "X[\"customer_country\"] = [\n",
    "    preprocess_country(country) for country in X[\"customer_country\"]\n",
    "]\n",
    "\n",
    "X_test[\"customer_country\"] = [\n",
    "    preprocess_country(country) for country in X_test[\"customer_country\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb64261",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Feature: Business Unit (\"business_unit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ddc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"business_unit\"] = X[\"business_unit\"].astype(\n",
    "    pd.CategoricalDtype(categories=[\"ID\", \"AS\", \"IT\", \"Solution\", \"CM\"])\n",
    ")\n",
    "X_test[\"business_unit\"] = X_test[\"business_unit\"].astype(\n",
    "    pd.CategoricalDtype(categories=[\"ID\", \"AS\", \"IT\", \"Solution\", \"CM\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0144a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Feature: Inquiry Type (\"inquiry_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inquiry_type_remap = {\n",
    "    # Quotation: Asking about the product itself.\n",
    "    \"Q\": [\n",
    "        \"Quotation or Purchase Consultation\",\n",
    "        \"Quotation or purchase consultation\",\n",
    "        \"Quotation or Purchase consultation\",\n",
    "        \"quotation_or_purchase_consultation\",\n",
    "        \"Purchase or Quotation\",\n",
    "        \"Purchase\",\n",
    "        \"Request for quotation or purchase\",\n",
    "        \"Sales Inquiry\",\n",
    "        \"sales\",\n",
    "        \"quotation_\",\n",
    "    ],\n",
    "    # Usage: Asking about how to use the product.\n",
    "    \"U\": [\n",
    "        \"Usage or Technical Consultation\",\n",
    "        \"Usage or technical consultation\",\n",
    "        \"usage or technical consultation\",\n",
    "        \"usage_or_technical_consultation\",\n",
    "        \"Technical Consultation\",\n",
    "        \"Technical Support\",\n",
    "        \"technical\",\n",
    "        \"technical_consultation\",\n",
    "        \"Request for technical consulting\",\n",
    "        \"Product Information\",\n",
    "        \"i want to know the details about it\",\n",
    "        \"first Info and pricing\",\n",
    "        \"Toi muon tim hieu thong tin ky thuat, gia ca cua sp de su dung\",\n",
    "        \"tôi cần tham khảo giá và giải pháp từ LG\",\n",
    "        \"Trainings\",\n",
    "    ],\n",
    "    \"O\": [\n",
    "        \"Other\",\n",
    "        \"Others\",\n",
    "        \"other_\",\n",
    "        \"other\",\n",
    "        \"others\",\n",
    "        \"Etc.\",\n",
    "        \"ETC.\",\n",
    "        \"Not specified\",\n",
    "        \"(Select ID_Needs)\",\n",
    "        \"IDB\",\n",
    "        \"Services\",\n",
    "        \"Request for Partnership\",\n",
    "        \"Request a Demo\",\n",
    "        \"Request for Distributorship\",\n",
    "        \"Customer Suggestions\",\n",
    "        *(\n",
    "            df_train[\"inquiry_type\"]\n",
    "            .value_counts()\n",
    "            .loc[df_train[\"inquiry_type\"].value_counts() < 10]\n",
    "            .index.tolist()\n",
    "        ),\n",
    "    ],\n",
    "}\n",
    "\n",
    "for key, value in inquiry_type_remap.items():\n",
    "    X.loc[X[\"inquiry_type\"].isin(value), \"inquiry_type\"] = key\n",
    "    X_test.loc[X_test[\"inquiry_type\"].isin(value), \"inquiry_type\"] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61066179",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_frequency = X[\"customer_country\"].value_counts(normalize=True)\n",
    "X[\"customer_country_frequency\"] = X[\"customer_country\"].map(country_frequency)\n",
    "X_test[\"customer_country_frequency\"] = X_test[\"customer_country\"].map(country_frequency)\n",
    "\n",
    "country_target = (\n",
    "    pd.concat([X, y], axis=1).groupby(\"customer_country\")[\"is_converted\"].mean()\n",
    ")\n",
    "X[\"customer_country_target\"] = X[\"customer_country\"].map(country_target)\n",
    "X_test[\"customer_country_target\"] = X_test[\"customer_country\"].map(country_target)\n",
    "\n",
    "owner_frequency = X[\"lead_owner\"].value_counts(normalize=True)\n",
    "X[\"lead_owner_frequency\"] = X[\"lead_owner\"].map(owner_frequency)\n",
    "X_test[\"lead_owner_frequency\"] = X_test[\"lead_owner\"].map(owner_frequency)\n",
    "\n",
    "owner_target = pd.concat([X, y], axis=1).groupby(\"lead_owner\")[\"is_converted\"].mean()\n",
    "X[\"lead_owner_target\"] = X[\"lead_owner\"].map(owner_target)\n",
    "X_test[\"lead_owner_target\"] = X_test[\"lead_owner\"].map(owner_target)\n",
    "\n",
    "business_weight = {\n",
    "    \"ID\": 0.064566116,\n",
    "    \"AS\": 0.026845638,\n",
    "    \"IT\": 0,\n",
    "    \"Solution\": 0.034482759,\n",
    "    \"CM\": 0,\n",
    "}\n",
    "\n",
    "X[\"com_reg_ver_win_rate_per_bu\"] = X[\"com_reg_ver_win_rate\"] * X[\"business_unit\"].map(\n",
    "    business_weight\n",
    ")\n",
    "X_test[\"com_reg_ver_win_rate_per_bu\"] = X_test[\"com_reg_ver_win_rate\"] * X_test[\n",
    "    \"business_unit\"\n",
    "].map(business_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67081d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 4. Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(\n",
    "    df: pd.DataFrame,\n",
    "    features=[\n",
    "        \"enterprise\",\n",
    "        \"business_unit\",\n",
    "        \"inquiry_type\",\n",
    "    ],\n",
    ") -> pd.DataFrame:\n",
    "    df_encoded = pd.get_dummies(df[features], columns=features)\n",
    "    df_encoded = df_encoded.apply(lambda x: x.astype(\"category\").cat.codes)\n",
    "    df = pd.concat([df, df_encoded], axis=1).drop(features, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "X = encode_features(X)\n",
    "X_test = encode_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d44381",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 5. Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = X[\"historical_existing_cnt\"].quantile(0.25)\n",
    "Q3 = X[\"historical_existing_cnt\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = pd.concat([X, pd.DataFrame({\"is_converted\": y})], axis=1)\n",
    "df = df[\n",
    "    (df[\"historical_existing_cnt\"] >= lower_bound)\n",
    "    & (df[\"historical_existing_cnt\"] <= upper_bound)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a8cef",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 6. Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef45166",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_transformer = Pipeline(steps=[(\"standardize\", StandardScaler())])\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"std\",\n",
    "            standard_transformer,\n",
    "            [\n",
    "                \"lead_desc_length\",\n",
    "                \"historical_existing_cnt\",\n",
    "                \"bant_submit\",\n",
    "                \"expected_timeline\",\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "column_transformer.set_output(transform=\"pandas\")\n",
    "\n",
    "X = column_transformer.fit_transform(X)\n",
    "X_test = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ed1ff",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 7. Feature Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\n",
    "    \"customer_country\",\n",
    "    \"customer_country.1\",\n",
    "    \"business_subarea\",\n",
    "    \"business_area\",\n",
    "    \"customer_idx\",\n",
    "    \"product_category\",\n",
    "    \"product_subcategory\",\n",
    "    \"product_modelname\",\n",
    "    \"customer_position\",\n",
    "    \"customer_job\",\n",
    "    \"customer_type\",\n",
    "    \"response_corporate\",\n",
    "    \"lead_owner\",\n",
    "]\n",
    "\n",
    "X = X.drop(features_to_drop, axis=1)  # type: ignore\n",
    "X_test = X_test.drop(features_to_drop, axis=1)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cf635",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af330e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_catboost_params(trial):\n",
    "    return {\n",
    "        \"iterations\": trial.suggest_int(\"cat__iterations\", 500, 1500),\n",
    "        \"learning_rate\": trial.suggest_float(\"cat__learning_rate\", 1e-3, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"cat__depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"cat__subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"cat__colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"cat__min_data_in_leaf\", 1, 100),\n",
    "        \"verbose\": False,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"auto_class_weights\": \"Balanced\",\n",
    "    }\n",
    "\n",
    "\n",
    "def optimize(X, y, n_trials) -> None:\n",
    "    def _optimize(trial, X, y):\n",
    "        model = CatBoostClassifier(**build_catboost_params(trial))\n",
    "        kfold, scores = StratifiedKFold(n_splits=5), []\n",
    "        for train_idx, val_idx in kfold.split(X, y):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction = model.predict(X_val)\n",
    "            prediction = np.where(prediction == \"True\", True, False)\n",
    "            scores.append(f1_score(y_val, prediction))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(\n",
    "        functools.partial(_optimize, X=X, y=y),  # type: ignore\n",
    "        n_trials=n_trials,\n",
    "        n_jobs=-1,\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "    joblib.dump(study, MODEL_FILE)\n",
    "\n",
    "\n",
    "if DO_OPTIMIZATION:\n",
    "    optimize(X, y, n_trials=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b38a96",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    print(col)\n",
    "    print(X[col].head())\n",
    "\n",
    "param_dict = {\n",
    "    \"cat\": {\n",
    "        \"verbose\": False,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"auto_class_weights\": \"Balanced\",\n",
    "    },\n",
    "}\n",
    "\n",
    "if DO_OPTIMIZATION:\n",
    "    optimization_results = joblib.load(MODEL_FILE).best_trial.params\n",
    "    for key, value in optimization_results.items():\n",
    "        model, param = [x.strip() for x in key.split(\"__\")]\n",
    "        param_dict[model][param] = value\n",
    "\n",
    "model = CatBoostClassifier(**param_dict[\"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a7319",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad26b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds, scores = (\n",
    "    StratifiedKFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True),\n",
    "    [],\n",
    ")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfolds.split(X, y)):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    sm = SMOTE(sampling_strategy=\"minority\", random_state=RANDOM_STATE)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)  # type: ignore\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_val)\n",
    "    prediction = np.where(prediction == \"True\", True, False)\n",
    "\n",
    "    print(f\"Accuracy (Fold {fold_idx}): {accuracy_score(y_val, prediction)}\")\n",
    "    print(f\"Precision (Fold {fold_idx}): {precision_score(y_val, prediction)}\")\n",
    "    print(f\"Recall (Fold {fold_idx}): {recall_score(y_val, prediction)}\")\n",
    "    print(f\"F1-Score (Fold {fold_idx}): {f1_score(y_val, prediction)}\")\n",
    "    print(\n",
    "        f\"ROC-AUC Score (Fold {fold_idx}): \"\n",
    "        + f\"{roc_auc_score(y_val, model.predict_proba(X_val)[:,1])}\\n\"\n",
    "    )\n",
    "\n",
    "    scores.append(f1_score(y_val, prediction))\n",
    "\n",
    "print(f\"Cross-Validation Average F1-Score: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35924efb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=\"minority\", random_state=RANDOM_STATE)\n",
    "X, y = sm.fit_resample(X, y)  # type: ignore\n",
    "model.fit(X, y)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction = np.where(prediction == \"True\", True, False)\n",
    "\n",
    "df_submission[\"is_converted\"] = prediction\n",
    "df_submission.to_csv(\"submission.csv\", index=False)\n",
    "print(df_submission[\"is_converted\"].value_counts())\n",
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
